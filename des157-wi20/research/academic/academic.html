<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans&display=swap" rel="stylesheet">
    <link href="styles.css" rel="stylesheet">
    <title>Interaction Design Academic Research</title>
</head>

<body>
    <div>
        <nav>
            <ul>
                <li>Academic Research</li>
                <li><a href= "index.html">Portal Page</a></li>
            </ul>
        </nav>
    </div>

    <header>Interaction Design Academic Research</header>

    <section>
        <p>The universal epidemic of sexism is popularly recognized in every industry. For my academic research, I focused on interactive spaces online and in the tech industry. The following several articles and websites discuss the gender discrimination and its consequences. In the article 'AI Can Be Sexist and Racist', highlights the significance of data and how subsequently skewed data leads to sexism. The growing scope of AI makes it vital to address the growing bias in the decision making outcomes.</p>
     </section>  
     
     <section>
        <p>Another article, 'AI Is the Future—But Where Are the Women?', discusses the lack of diversity in the tech industry and how this might lead to a biased thinking. Due to male-dominance in the tech industry, women are a small minority.  According to this article, 12% were women that contributed work to three leading machine learning conferences in 2017 in comparison to 88% men. Moreover, women in AI research say that the field can be unwelcoming and even hostile to women. This lack of diversity is not only concerning from an ethical standpoint. The underrepresentation impacts the research process and therefore the results. This article states that “Microsoft found that facial analysis services that IBM and Microsoft offered to businesses were less accurate for darker skin tones. The companies’ algorithms were near perfect at identifying the gender of men with lighter skin, but frequently erred when presented with photos of women with dark skin.”This industry gender bias leads to the skewed data that in return makes prejudiced decisions. </p>
    </section>

    <section>
        <p>These gender biases are harmful when you approach them with a binary perspective. This is even worse when taken into account transgender or non-binary individuals. A number of machine-learning data is based on people being categorized into male or female. This impacts all the research that companies collect to understand their users better. However, not only does this result in skewed data but also harms transgender people, as well as those who don't look stereotypically male or female. The author in the article 'AI Software Defines People as Male or Female. That’s a Problem.' states that "there is a fatal flaw: The way a computer sees gender isn't always the same way people see it".   </p>
    </section>
    
    <section>
        <h2> Bibliography</h2>
        <p>Nature Editorial. “AI Can Be Sexist and Racist — It’s Time to Make It Fair.” Nature, 18 July 2018, www.nature.com/articles/d41586-018-05707-8?error=cookies_not_supported&code=eb373916-3267-4a63-b786-8902ea2ac4ea.</p>
        <p>Simonite, Tom. “AI Is the Future—But Where Are the Women?” Wired, 17 Aug. 2018, www.wired.com/story/artificial-intelligence-researchers-gender-imbalance. </p>
        <p>Rachel Metz, CNN Business. “AI Software Defines People as Male or Female. That’s a Problem.” CNN, 21 Nov. 2019, edition.cnn.com/2019/11/21/tech/ai-gender-recognition-problem/index.html.</p>
    </section>

    <footer>
        <p><a href="http://validator.w3.org/check?uri=referer">Valid HTML</a></p>
        <p><a href="https://jigsaw.w3.org/css-validator/check/referer">Valid CSS</a></p>
    </footer>
</body>
</html>